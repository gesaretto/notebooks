{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesser\n",
    "\n",
    "1. Open `corpus.txt`, read it line by line.\n",
    "2. Eliminate everything that is placed in parentheses (stage directions).\n",
    "3. If line is a character's line, extract character's name and line; add to the dictionary:\n",
    "    1. if character's name exists in the dictionary, add to list of utts by preexisting character;\n",
    "    2. if character's name is not in the dictionary, add new character entry.\n",
    "    \n",
    "1. Make additional dictionary of BOWs (lists within the list).\n",
    "    1. Create new dictionary;\n",
    "    1. for each entry in the utts_dictionary, open each sentence, tokenize it, lemmatize it, remove punctuation and stop_words;\n",
    "    1. then convert sentence into BOW and add it to list;\n",
    "    1. append list of bows and character as key to dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "from seinfeld_functions import lemmatize_with_pos, preprocess_sentence, bow_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances_dictionary = {}\n",
    "bows_dictionary = {}\n",
    "total_bows_per_character = {}\n",
    "characters_line_regex = \"^([A-Z]+): (.{1,250})$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"corpus.txt\", \"r\", encoding=\"utf8\") as corpus:\n",
    "    for line in corpus.readlines():\n",
    "        cleaned_line = re.sub(\"\\(.+\\)\", \"\", line)\n",
    "        cleaned_line = re.sub(\"\\[.+\\]\", \"\", line)\n",
    "        match_line = re.search(characters_line_regex, cleaned_line)\n",
    "        if match_line and match_line.group(1) in utterances_dictionary:\n",
    "            utterances_dictionary[match_line.group(1)].append(match_line.group(2))\n",
    "        elif match_line:\n",
    "            utterances_dictionary[match_line.group(1)] = [match_line.group(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in utterances_dictionary:\n",
    "    bow_list = []\n",
    "    characters_bow = set() \n",
    "    for utterance in utterances_dictionary[key]:\n",
    "        preprocessed_utterance = preprocess_sentence(utterance)\n",
    "        utterance_bow = bow_sentence(preprocessed_utterance)\n",
    "        for word in utterance_bow:\n",
    "            characters_bow.add(word)\n",
    "        bow_list.append(utterance_bow)\n",
    "    bows_dictionary[key] = bow_list\n",
    "    total_bows_per_character[key] = characters_bow\n",
    "    \n",
    "# print(bows_dictionary[\"NEWMAN\"])\n",
    "# print(total_bows_per_character[\"NEWMAN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(utterances_dictionary, open(\"seinfeld_utterances_dictionary.p\", \"wb\"))\n",
    "pickle.dump(bows_dictionary, open(\"seinfeld_bows_dictionary.p\", \"wb\"))\n",
    "pickle.dump(total_bows_per_character, open(\"seinfeld_bows_per_character.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
